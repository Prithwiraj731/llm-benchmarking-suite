{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62da7d94",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# BLEU AND ROUGE-L EVALUATION - FOUR-WHEELER MODEL (LEXUS)\n",
    "# Metrics: BLEU-1, BLEU-2, BLEU-4, ROUGE-L\n",
    "# ==============================================================================\n",
    "\n",
    "# ========== CELL 1: Install Packages ==========\n",
    "!pip install -q accelerate bitsandbytes transformers rouge-score nltk\n",
    "\n",
    "# Note: After running Cell 1, restart runtime then run cells 2-10\n",
    "\n",
    "\n",
    "# ========== CELL 2: Import Libraries ==========\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "import time\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "\n",
    "\n",
    "# ========== CELL 3: Define Dataset ==========\n",
    "dataset = [\n",
    "    {\n",
    "        \"question\": \"What is the purpose of the SRS airbags in the vehicle?\", \n",
    "        \"answer\": \"The SRS airbags are designed to deploy in the event of a crash or sudden stop, providing protection for the occupants of the vehicle.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the function of the steering wheel?\", \n",
    "        \"answer\": \"Adjusting the steering wheel\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the procedure for connecting a Bluetooth audio player?\", \n",
    "        \"answer\": \"Connecting a Bluetooth audio player involves selecting a Bluetooth device, registering the device, and then connecting it to the vehicle's Bluetooth system.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"If your vehicle overheats\", \n",
    "        \"answer\": \"Check the coolant level and condition, and refer to the owner's manual for guidance on how to address the issue.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the recommended approach for replacing genuine Lexus parts or accessories in the vehicle?\", \n",
    "        \"answer\": \"Lexus recommends using genuine Lexus parts or accessories for replacement, but other parts or accessories of matching quality can also be used.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the recommended procedure for removing and disposing of the SRS airbag and seat belt pretensioner devices from a Lexus vehicle before scrapping?\", \n",
    "        \"answer\": \"Have the systems removed and disposed of by an authorized Lexus dealer or a duly qualified and equipped professional.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# ========== CELL 4: Define BLEU and ROUGE Functions ==========\n",
    "def calculate_bleu(prediction, reference):\n",
    "    \"\"\"Calculate BLEU-1, BLEU-2, and BLEU-4 scores\"\"\"\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    reference_tokens = [reference.lower().split()]\n",
    "    prediction_tokens = prediction.lower().split()\n",
    "    \n",
    "    if len(prediction_tokens) == 0:\n",
    "        return 0.0, 0.0, 0.0\n",
    "    \n",
    "    bleu1 = sentence_bleu(reference_tokens, prediction_tokens, \n",
    "                         weights=(1, 0, 0, 0), smoothing_function=smoothie)\n",
    "    bleu2 = sentence_bleu(reference_tokens, prediction_tokens, \n",
    "                         weights=(0.5, 0.5, 0, 0), smoothing_function=smoothie)\n",
    "    bleu4 = sentence_bleu(reference_tokens, prediction_tokens, \n",
    "                         weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothie)\n",
    "    \n",
    "    return bleu1, bleu2, bleu4\n",
    "\n",
    "def calculate_rouge(prediction, reference):\n",
    "    \"\"\"Calculate ROUGE-L F-measure score\"\"\"\n",
    "    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "    scores = scorer.score(reference, prediction)\n",
    "    return scores['rougeL'].fmeasure\n",
    "\n",
    "\n",
    "# ========== CELL 5: Configure Model ==========\n",
    "model_name = \"Prithwiraj731/FourWheeler-Gemma-2B\"\n",
    "\n",
    "print(\"Model Configuration:\")\n",
    "print(f\"  Model: {model_name}\")\n",
    "print(f\"  Type: Full merged model\")\n",
    "\n",
    "\n",
    "# ========== CELL 6: Load Model ==========\n",
    "print(\"\\nLoading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "print(\"Loading full model with 4-bit quantization...\")\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    dtype=torch.float16\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(\"Model loaded successfully\\n\")\n",
    "\n",
    "\n",
    "# ========== CELL 7: Define Answer Generation Function ==========\n",
    "def generate_answer(question, max_new_tokens=100):\n",
    "    \"\"\"Generate answer using optimized settings\"\"\"\n",
    "    prompt = f\"{question}\\n\"\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=0.1,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            repetition_penalty=1.2\n",
    "        )\n",
    "    \n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    answer = generated_text[len(prompt):].strip()\n",
    "    answer = answer.split('\\n')[0].strip()\n",
    "    \n",
    "    if not answer or len(answer.strip()) == 0:\n",
    "        answer = \"No answer generated\"\n",
    "    \n",
    "    return answer\n",
    "\n",
    "\n",
    "# ========== CELL 8: Generate Predictions and Calculate Metrics ==========\n",
    "print(\"=\"*70)\n",
    "print(\"GENERATING ANSWERS AND CALCULATING BLEU/ROUGE METRICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results = []\n",
    "all_bleu1, all_bleu2, all_bleu4, all_rouge = [], [], [], []\n",
    "generation_times = []\n",
    "\n",
    "for i, item in enumerate(dataset):\n",
    "    question = item[\"question\"]\n",
    "    reference = item[\"answer\"]\n",
    "    \n",
    "    print(f\"\\nQuestion {i+1}/{len(dataset)}\")\n",
    "    print(f\"Q: {question[:70]}...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    prediction = generate_answer(question)\n",
    "    gen_time = time.time() - start_time\n",
    "    generation_times.append(gen_time)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    bleu1, bleu2, bleu4 = calculate_bleu(prediction, reference)\n",
    "    rouge_l = calculate_rouge(prediction, reference)\n",
    "    \n",
    "    all_bleu1.append(bleu1)\n",
    "    all_bleu2.append(bleu2)\n",
    "    all_bleu4.append(bleu4)\n",
    "    all_rouge.append(rouge_l)\n",
    "    \n",
    "    results.append({\n",
    "        'question': question,\n",
    "        'reference': reference,\n",
    "        'prediction': prediction,\n",
    "        'bleu1': bleu1,\n",
    "        'bleu2': bleu2,\n",
    "        'bleu4': bleu4,\n",
    "        'rouge_l': rouge_l\n",
    "    })\n",
    "    \n",
    "    print(f\"Generated: {prediction[:70]}...\")\n",
    "    print(f\"Reference: {reference[:70]}...\")\n",
    "    print(f\"BLEU-1: {bleu1:.4f} | BLEU-2: {bleu2:.4f} | BLEU-4: {bleu4:.4f}\")\n",
    "    print(f\"ROUGE-L: {rouge_l:.4f}\")\n",
    "    print(f\"Time: {gen_time:.2f}s\")\n",
    "\n",
    "avg_gen_time = sum(generation_times) / len(generation_times)\n",
    "print(f\"\\nAverage generation time: {avg_gen_time:.2f}s\")\n",
    "\n",
    "\n",
    "# ========== CELL 9: Display Summary Results ==========\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FOUR-WHEELER MODEL - BLEU/ROUGE-L RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "avg_bleu1 = sum(all_bleu1) / len(all_bleu1)\n",
    "avg_bleu2 = sum(all_bleu2) / len(all_bleu2)\n",
    "avg_bleu4 = sum(all_bleu4) / len(all_bleu4)\n",
    "avg_rouge = sum(all_rouge) / len(all_rouge)\n",
    "\n",
    "print(f\"\\nAverage Scores:\")\n",
    "print(f\"  BLEU-1:  {avg_bleu1:.4f} ({avg_bleu1*100:.2f}%)\")\n",
    "print(f\"  BLEU-2:  {avg_bleu2:.4f} ({avg_bleu2*100:.2f}%)\")\n",
    "print(f\"  BLEU-4:  {avg_bleu4:.4f} ({avg_bleu4*100:.2f}%)\")\n",
    "print(f\"  ROUGE-L: {avg_rouge:.4f} ({avg_rouge*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nMetric Definitions:\")\n",
    "print(\"  - BLEU-1: Unigram precision (individual word matches)\")\n",
    "print(\"  - BLEU-2: Bigram precision (2-word phrase matches)\")\n",
    "print(\"  - BLEU-4: 4-gram precision (4-word phrase matches)\")\n",
    "print(\"  - ROUGE-L: Longest common subsequence F-measure\")\n",
    "\n",
    "\n",
    "# ========== CELL 10: Results DataFrame ==========\n",
    "results_df = pd.DataFrame({\n",
    "    'Question': [r['question'][:40] + '...' if len(r['question']) > 40 else r['question'] for r in results],\n",
    "    'BLEU-1': [f\"{r['bleu1']:.4f}\" for r in results],\n",
    "    'BLEU-2': [f\"{r['bleu2']:.4f}\" for r in results],\n",
    "    'BLEU-4': [f\"{r['bleu4']:.4f}\" for r in results],\n",
    "    'ROUGE-L': [f\"{r['rouge_l']:.4f}\" for r in results]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DETAILED RESULTS TABLE\")\n",
    "print(\"=\"*70)\n",
    "display(results_df)\n",
    "\n",
    "\n",
    "# ========== CELL 11: Save Results (Optional) ==========\n",
    "# Uncomment to save and download results\n",
    "\n",
    "# results_df.to_csv('bleu_rouge_4wheeler_results.csv', index=False)\n",
    "# print(\"\\nResults saved to 'bleu_rouge_4wheeler_results.csv'\")\n",
    "\n",
    "# from google.colab import files\n",
    "# files.download('bleu_rouge_4wheeler_results.csv')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
